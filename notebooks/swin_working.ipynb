{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T11:51:39.718555Z",
          "iopub.status.busy": "2023-07-11T11:51:39.718190Z",
          "iopub.status.idle": "2023-07-11T11:51:43.776956Z",
          "shell.execute_reply": "2023-07-11T11:51:43.775793Z",
          "shell.execute_reply.started": "2023-07-11T11:51:39.718525Z"
        },
        "id": "UP9KnqiD1rav",
        "outputId": "0b206acb-91be-4e54-b3f3-4b2274c72872",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.21.0 typeguard-2.13.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as ans\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras import *\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.layers import Dense, Input, UpSampling2D, Conv2DTranspose, Conv2D, add, Add,\\\n",
        "                    Lambda, Concatenate, AveragePooling2D, BatchNormalization, GlobalAveragePooling2D, \\\n",
        "                    Add, LayerNormalization, Activation, LeakyReLU, SeparableConv2D, Dropout\n",
        "try:\n",
        "    import tensorflow_addons as tfa\n",
        "except:\n",
        "    !pip install tensorflow_addons\n",
        "    import tensorflow_addons as tfa\n",
        "    from tensorflow_addons.layers import InstanceNormalization\n",
        "try:\n",
        "    import gdown\n",
        "except:\n",
        "    !pip install gdown --quiet\n",
        "    import gdown\n",
        "\n",
        "try:\n",
        "    from imutils import paths\n",
        "except:\n",
        "    !pip install imutils  --quiet\n",
        "    from imutils import paths\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "import PIL\n",
        "import glob\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import collections\n",
        "from collections import *\n",
        "from itertools import repeat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T11:54:04.585445Z",
          "iopub.status.busy": "2023-07-11T11:54:04.585047Z",
          "iopub.status.idle": "2023-07-11T11:54:04.594043Z",
          "shell.execute_reply": "2023-07-11T11:54:04.593072Z",
          "shell.execute_reply.started": "2023-07-11T11:54:04.585416Z"
        },
        "id": "x5OxGwmV1rbE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class MLP(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "        this class is a implementation of the mlp block described in the swin transformer paper, which contains\n",
        "        2 fully connected layer with GelU activation.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, drop=0.):\n",
        "        \"\"\"\n",
        "            Params:\n",
        "                input_neurons(dtype: int)   : input dimension for the mlp block, it needed only for .summary() method.\n",
        "                hidden_neurons(dtype: int)  : number of neurons in the hidden\n",
        "                                              layer(fully connected layer).\n",
        "                output_neurons(dtype: iny)  ; number of neurons in the last\n",
        "                                              layer(fully connected layer) of mlp.\n",
        "                act_type(type: str)         ; type of activation needed. in paper, GeLU is used.\n",
        "                dropout_rate(dtype: float)  : dropout rate in the dropout layer.\n",
        "                prefix(type: str)           : used for the naming the layers.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.fc1 = Dense(hidden_features, name=f'mlp/fc1')\n",
        "        self.fc2 = Dense(out_features, name=f'mlp/fc2')\n",
        "        self.drop = Dropout(drop)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = tf.keras.activations.gelu(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T11:54:04.966368Z",
          "iopub.status.busy": "2023-07-11T11:54:04.965588Z",
          "iopub.status.idle": "2023-07-11T11:54:04.978174Z",
          "shell.execute_reply": "2023-07-11T11:54:04.977088Z",
          "shell.execute_reply.started": "2023-07-11T11:54:04.966319Z"
        },
        "id": "NJjeB6sA1rbG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def window_partition(x: tf.Tensor, window_size: int):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        x: (B, H, W, C)\n",
        "        window_size (int): window size\n",
        "    Returns:\n",
        "        windows: (num_windows*B, window_size, window_size, C)\n",
        "    \"\"\"\n",
        "    B, H, W, C = tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2], tf.shape(x)[3]\n",
        "\n",
        "    x = tf.reshape(\n",
        "        x, (B, H // window_size, window_size, W // window_size, window_size, C)\n",
        "    )\n",
        "    windows = tf.transpose(x, [0, 1, 3, 2, 4, 5])\n",
        "    windows = tf.reshape(windows, (-1, window_size, window_size, C))\n",
        "    return windows\n",
        "\n",
        "\n",
        "def window_reverse(windows: tf.Tensor, window_size: int, H: int, W: int):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        windows: (num_windows*B, window_size, window_size, C)\n",
        "        window_size (int): Window size\n",
        "        H (int): Height of image\n",
        "        W (int): Width of image\n",
        "    Returns:\n",
        "        x: (B, H, W, C)\n",
        "    \"\"\"\n",
        "    B = tf.shape(windows)[0] // tf.cast(\n",
        "        H * W / window_size / window_size, dtype=\"int32\"\n",
        "    )\n",
        "\n",
        "    x = tf.reshape(\n",
        "        windows,\n",
        "        (\n",
        "            B,\n",
        "            H // window_size,\n",
        "            W // window_size,\n",
        "            window_size,\n",
        "            window_size,\n",
        "            -1,\n",
        "        ),\n",
        "    )\n",
        "    x = tf.transpose(x, [0, 1, 3, 2, 4, 5])\n",
        "    return tf.reshape(x, (B, H, W, -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T11:54:06.994625Z",
          "iopub.status.busy": "2023-07-11T11:54:06.994247Z",
          "iopub.status.idle": "2023-07-11T11:54:07.020252Z",
          "shell.execute_reply": "2023-07-11T11:54:07.019147Z",
          "shell.execute_reply.started": "2023-07-11T11:54:06.994593Z"
        },
        "id": "TJ81PLxI1rbQ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Code copied and modified from\n",
        "https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/swin_transformer.py\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import collections.abc\n",
        "from typing import Tuple, Union\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "def get_relative_position_index(win_h, win_w):\n",
        "    # get pair-wise relative position index for each token inside the window\n",
        "    xx, yy = tf.meshgrid(range(win_h), range(win_w))\n",
        "    coords = tf.stack([yy, xx], axis=0)  # [2, Wh, Ww]\n",
        "    coords_flatten = tf.reshape(coords, [2, -1])  # [2, Wh*Ww]\n",
        "\n",
        "    relative_coords = (\n",
        "        coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
        "    )  # [2, Wh*Ww, Wh*Ww]\n",
        "    relative_coords = tf.transpose(\n",
        "        relative_coords, perm=[1, 2, 0]\n",
        "    )  # [Wh*Ww, Wh*Ww, 2]\n",
        "\n",
        "    xx = (relative_coords[:, :, 0] + win_h - 1) * (2 * win_w - 1)\n",
        "    yy = relative_coords[:, :, 1] + win_w - 1\n",
        "    relative_coords = tf.stack([xx, yy], axis=-1)\n",
        "\n",
        "    return tf.reduce_sum(relative_coords, axis=-1)  # [Wh*Ww, Wh*Ww]\n",
        "\n",
        "\n",
        "class WindowAttention(layers.Layer):\n",
        "    \"\"\"Window based multi-head self attention (W-MSA) module with relative position bias.\n",
        "    It supports both of shifted and non-shifted window.\n",
        "\n",
        "    Args:\n",
        "        dim (int): Number of input channels.\n",
        "        num_heads (int): Number of attention heads.\n",
        "        head_dim (int): Number of channels per head (dim // num_heads if not set)\n",
        "        window_size (tuple[int]): The height and width of the window.\n",
        "        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True\n",
        "        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0\n",
        "        proj_drop (float, optional): Dropout ratio of output. Default: 0.0\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim, num_heads, head_dim=None, window_size=7,\n",
        "                     qkv_bias=True, attn_drop=0.0, proj_drop=0.0, **kwargs):\n",
        "\n",
        "        super(WindowAttention, self).__init__(**kwargs)\n",
        "\n",
        "        self.dim = dim\n",
        "        self.window_size = (\n",
        "            window_size\n",
        "            if isinstance(window_size, collections.abc.Iterable)\n",
        "            else (window_size, window_size)\n",
        "        )  # Wh, Ww\n",
        "        self.win_h, self.win_w = self.window_size\n",
        "        self.window_area = self.win_h * self.win_w\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = (dim // num_heads)\n",
        "        self.attn_dim = self.head_dim * num_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "\n",
        "        # get pair-wise relative position index for each token inside the window\n",
        "        self.relative_position_index = get_relative_position_index(\n",
        "            self.win_h, self.win_w\n",
        "        )\n",
        "\n",
        "        self.qkv = layers.Dense(\n",
        "            self.attn_dim * 3, use_bias=qkv_bias, name=\"attention_qkv\"\n",
        "        )\n",
        "        self.attn_drop = layers.Dropout(attn_drop)\n",
        "        self.proj = layers.Dense(dim, name=\"attention_projection\")\n",
        "        self.proj_drop = layers.Dropout(proj_drop)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.relative_position_bias_table = self.add_weight(\n",
        "            shape=((2 * self.win_h - 1) * (2 * self.win_w - 1), self.num_heads),\n",
        "            initializer=\"zeros\",\n",
        "            trainable=True,\n",
        "            name=\"relative_position_bias_table\",\n",
        "        )\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def _get_rel_pos_bias(self) -> tf.Tensor:\n",
        "        relative_position_bias = tf.gather(\n",
        "            self.relative_position_bias_table,\n",
        "            self.relative_position_index,\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.transpose(relative_position_bias, [2, 0, 1])\n",
        "\n",
        "    def call(\n",
        "        self, x, mask=None, return_attns=False\n",
        "    ) -> Union[tf.Tensor, Tuple[tf.Tensor, tf.Tensor]]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: input features with shape of (num_windows*B, N, C)\n",
        "            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None\n",
        "        \"\"\"\n",
        "        B_, N, C = tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2]\n",
        "        print(tf.shape(x), B_ * N *C)\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = tf.reshape(qkv, (B_, N, 3, self.num_heads, -1))\n",
        "        qkv = tf.transpose(qkv, (2, 0, 3, 1, 4))\n",
        "\n",
        "        q, k, v = tf.unstack(qkv, 3)\n",
        "\n",
        "        scale = tf.cast(self.scale, dtype=qkv.dtype)\n",
        "        q = q * scale\n",
        "        attn = tf.matmul(q, tf.transpose(k, perm=[0, 1, 3, 2]))\n",
        "        attn = attn + self._get_rel_pos_bias()\n",
        "\n",
        "        if mask is not None:\n",
        "            num_win = tf.shape(mask)[0]\n",
        "            attn = tf.reshape(\n",
        "                attn, (B_ // num_win, num_win, self.num_heads, N, N)\n",
        "            )\n",
        "            attn = attn + tf.expand_dims(mask, 1)[None, ...]\n",
        "\n",
        "            attn = tf.reshape(attn, (-1, self.num_heads, N, N))\n",
        "            attn = tf.nn.softmax(attn, -1)\n",
        "        else:\n",
        "            attn = tf.nn.softmax(attn, -1)\n",
        "\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = tf.matmul(attn, v)\n",
        "        print(x.shape)\n",
        "        x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "        x = tf.reshape(x, (B_, N, C))\n",
        "\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T11:54:12.735220Z",
          "iopub.status.busy": "2023-07-11T11:54:12.734831Z",
          "iopub.status.idle": "2023-07-11T11:54:12.743822Z",
          "shell.execute_reply": "2023-07-11T11:54:12.742716Z",
          "shell.execute_reply.started": "2023-07-11T11:54:12.735187Z"
        },
        "id": "sf-sFqnL1rbW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def drop_path(inputs, drop_prob, is_training):\n",
        "    if (not is_training) or (drop_prob == 0.):\n",
        "        return inputs\n",
        "\n",
        "    # Compute keep_prob\n",
        "    keep_prob = 1.0 - drop_prob\n",
        "\n",
        "    # Compute drop_connect tensor\n",
        "    random_tensor = keep_prob\n",
        "    shape = (tf.shape(inputs)[0],) + (1,) * \\\n",
        "        (len(tf.shape(inputs)) - 1)\n",
        "    random_tensor += tf.random.uniform(shape, dtype=inputs.dtype)\n",
        "    binary_tensor = tf.floor(random_tensor)\n",
        "    output = tf.math.divide(inputs, keep_prob) * binary_tensor\n",
        "    return output\n",
        "\n",
        "\n",
        "class DropPath(tf.keras.layers.Layer):\n",
        "    def __init__(self, drop_prob=None):\n",
        "        super().__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "    def call(self, x, training=None):\n",
        "        return drop_path(x, self.drop_prob, training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T11:54:13.093952Z",
          "iopub.status.busy": "2023-07-11T11:54:13.093594Z",
          "iopub.status.idle": "2023-07-11T11:54:13.118447Z",
          "shell.execute_reply": "2023-07-11T11:54:13.117073Z",
          "shell.execute_reply.started": "2023-07-11T11:54:13.093920Z"
        },
        "id": "HJGlG0zg1rbW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class SwinTransformerBlock(keras.Model):\n",
        "    \"\"\"Swin Transformer Block.\n",
        "\n",
        "    Args:\n",
        "        dim (int): Number of input channels.\n",
        "        input_resolution (tuple[int]): Input resulotion.\n",
        "        window_size (int): Window size.\n",
        "        num_heads (int): Number of attention heads.\n",
        "        head_dim (int): Enforce the number of channels per head\n",
        "        shift_size (int): Shift size for SW-MSA.\n",
        "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
        "        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n",
        "        drop (float, optional): Dropout rate. Default: 0.0\n",
        "        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n",
        "        drop_path (float, optional): Stochastic depth rate. Default: 0.0\n",
        "        norm_layer (layers.Layer, optional): Normalization layer.  Default: layers.LayerNormalization\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim, input_resolution, num_heads=4, head_dim=None,\n",
        "                 window_size=7, shift_size=0, mlp_ratio=4.0, qkv_bias=True,\n",
        "                 drop=0.0, attn_drop=0.0, drop_path=0.0,\n",
        "                 norm_layer=LayerNormalization, **kwargs,):\n",
        "        super(SwinTransformerBlock, self).__init__(**kwargs)\n",
        "\n",
        "        self.dim = dim\n",
        "        self.input_resolution = input_resolution\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size\n",
        "        self.mlp_ratio = mlp_ratio\n",
        "        if min(self.input_resolution) <= self.window_size:\n",
        "            # if window size is larger than input resolution, we don't partition windows\n",
        "            self.shift_size = 0\n",
        "            self.window_size = min(self.input_resolution)\n",
        "        assert (\n",
        "            0 <= self.shift_size < self.window_size\n",
        "        ), \"shift_size must in 0-window_size\"\n",
        "\n",
        "        self.norm1 = norm_layer(epsilon=1e-5)\n",
        "        self.attn = WindowAttention(\n",
        "            dim=dim,\n",
        "            num_heads=num_heads,\n",
        "            head_dim=head_dim,\n",
        "            window_size=window_size\n",
        "            if isinstance(window_size, collections.abc.Iterable)\n",
        "            else (window_size, window_size),\n",
        "            qkv_bias=qkv_bias,\n",
        "            attn_drop=attn_drop,\n",
        "            proj_drop=drop,\n",
        "            name=\"window_attention\",\n",
        "        )\n",
        "\n",
        "        self.drop_path = (\n",
        "            DropPath(drop_path) if drop_path > 0.0 else tf.identity\n",
        "        )\n",
        "        self.norm2 = norm_layer(epsilon=1e-5)\n",
        "       # self.mlp = mlp_block(\n",
        "        #    dropout_rate=drop, hidden_units=[int(dim * mlp_ratio), dim]\n",
        "        #)\n",
        "\n",
        "        self.mlp = MLP(\n",
        "            in_features=dim,\n",
        "            out_features=dim,\n",
        "            hidden_features=int(dim * mlp_ratio),\n",
        "            drop=drop\n",
        "        )\n",
        "\n",
        "        if self.shift_size > 0:\n",
        "            # `get_attn_mask()` uses NumPy to make in-place assignments.\n",
        "            # Since this is done during initialization, it's okay.\n",
        "            self.attn_mask = self.get_attn_mask()\n",
        "        else:\n",
        "            self.attn_mask = None\n",
        "\n",
        "    def get_attn_mask(self):\n",
        "        # calculate attention mask for SW-MSA\n",
        "        H, W = self.input_resolution\n",
        "        img_mask = np.zeros((1, H, W, 1))  # [1, H, W, 1]\n",
        "        cnt = 0\n",
        "        for h in (\n",
        "            slice(0, -self.window_size),\n",
        "            slice(-self.window_size, -self.shift_size),\n",
        "            slice(-self.shift_size, None),\n",
        "        ):\n",
        "            for w in (\n",
        "                slice(0, -self.window_size),\n",
        "                slice(-self.window_size, -self.shift_size),\n",
        "                slice(-self.shift_size, None),\n",
        "            ):\n",
        "                img_mask[:, h, w, :] = cnt\n",
        "                cnt += 1\n",
        "\n",
        "        img_mask = tf.convert_to_tensor(img_mask, dtype=\"float32\")\n",
        "        mask_windows = window_partition(\n",
        "            img_mask, self.window_size\n",
        "        )  # [num_win, window_size, window_size, 1]\n",
        "        mask_windows = tf.reshape(\n",
        "            mask_windows, (-1, self.window_size * self.window_size)\n",
        "        )\n",
        "        attn_mask = tf.expand_dims(mask_windows, 1) - tf.expand_dims(\n",
        "            mask_windows, 2\n",
        "        )\n",
        "        attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
        "        return tf.where(attn_mask == 0, 0.0, attn_mask)\n",
        "\n",
        "    def call(self, x):\n",
        "        H, W = self.input_resolution\n",
        "        B, L, C = tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2]\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = tf.reshape(x, (B, H, W, C))\n",
        "\n",
        "        # cyclic shift\n",
        "        if self.shift_size > 0:\n",
        "            shifted_x = tf.roll(\n",
        "                x, shift=(-self.shift_size, -self.shift_size), axis=(1, 2)\n",
        "            )\n",
        "        else:\n",
        "            shifted_x = x\n",
        "\n",
        "        # partition windows\n",
        "        x_windows = window_partition(\n",
        "            shifted_x, self.window_size\n",
        "        )  # [num_win*B, window_size, window_size, C]\n",
        "        x_windows = tf.reshape(\n",
        "            x_windows, (-1, self.window_size * self.window_size, C)\n",
        "        )  # [num_win*B, window_size*window_size, C]\n",
        "\n",
        "        # W-MSA/SW-MSA\n",
        "\n",
        "        attn_windows = self.attn(\n",
        "                x_windows, mask=self.attn_mask\n",
        "            )  # [num_win*B, window_size*window_size, C]\n",
        "        # merge windows\n",
        "        attn_windows = tf.reshape(\n",
        "            attn_windows, (-1, self.window_size, self.window_size, C)\n",
        "        )\n",
        "        shifted_x = window_reverse(\n",
        "            attn_windows, self.window_size, H, W\n",
        "        )  # [B, H', W', C]\n",
        "\n",
        "        # reverse cyclic shift\n",
        "        if self.shift_size > 0:\n",
        "            x = tf.roll(\n",
        "                shifted_x,\n",
        "                shift=(self.shift_size, self.shift_size),\n",
        "                axis=(1, 2),\n",
        "            )\n",
        "        else:\n",
        "            x = shifted_x\n",
        "        x = tf.reshape(x, (B, H * W, C))\n",
        "\n",
        "        # FFN\n",
        "        x = shortcut + self.drop_path(x)\n",
        "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T11:54:13.715530Z",
          "iopub.status.busy": "2023-07-11T11:54:13.715153Z",
          "iopub.status.idle": "2023-07-11T11:54:13.726115Z",
          "shell.execute_reply": "2023-07-11T11:54:13.725072Z",
          "shell.execute_reply.started": "2023-07-11T11:54:13.715502Z"
        },
        "id": "RABMd-RP1rbd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class PatchMerging(keras.layers.Layer):\n",
        "    \"\"\" Patch Merging Layer.\n",
        "    Args:\n",
        "        input_resolution (tuple[int]): Resolution of input feature.\n",
        "        dim (int): Number of input channels.\n",
        "        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n",
        "    \"\"\"\n",
        "    def __init__(self, input_resolution, dim, norm_layer=LayerNormalization, **kwargs):\n",
        "        super(PatchMerging, self).__init__(**kwargs)\n",
        "        self.input_resolution = input_resolution\n",
        "        self.dim = dim\n",
        "        self.reduction = Dense(2 * dim, use_bias=False, name='downsample_reduction')\n",
        "        self.norm = LayerNormalization(epsilon=1e-5)\n",
        "\n",
        "    def call(self, x):\n",
        "        \"\"\"\n",
        "        x: B, H * W, C\n",
        "        \"\"\"\n",
        "        H, W = self.input_resolution\n",
        "        B, L, C = tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2]\n",
        "        assert L == H * W, \"input feature has wrong size\"\n",
        "        assert H % 2 == 0 and W % 2 == 0, f\"x size ({H}*{W}) are not even.\"\n",
        "\n",
        "        x = tf.reshape(x, shape=[-1, H, W, C])\n",
        "\n",
        "        x0 = x[:, 0::2, 0::2, :]  # B H/2 W/2 C\n",
        "        x1 = x[:, 1::2, 0::2, :]  # B H/2 W/2 C\n",
        "        x2 = x[:, 0::2, 1::2, :]  # B H/2 W/2 C\n",
        "        x3 = x[:, 1::2, 1::2, :]  # B H/2 W/2 C\n",
        "        x = tf.concat([x0, x1, x2, x3], axis=-1)\n",
        "\n",
        "        x = tf.reshape(x, (B, -1, 4 * C))\n",
        "\n",
        "        x = self.norm(x)\n",
        "        x = self.reduction(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T11:54:14.366663Z",
          "iopub.status.busy": "2023-07-11T11:54:14.365947Z",
          "iopub.status.idle": "2023-07-11T11:54:14.380891Z",
          "shell.execute_reply": "2023-07-11T11:54:14.379761Z",
          "shell.execute_reply.started": "2023-07-11T11:54:14.366626Z"
        },
        "id": "oXQns7461rbh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class BasicLayer(keras.Model):\n",
        "    \"\"\"A basic Swin Transformer layer for one stage.\n",
        "\n",
        "    Args:\n",
        "        dim (int): Number of input channels.\n",
        "        input_resolution (tuple[int]): Input resolution.\n",
        "        depth (int): Number of blocks.\n",
        "        num_heads (int): Number of attention heads.\n",
        "        head_dim (int): Channels per head (dim // num_heads if not set)\n",
        "        window_size (int): Local window size.\n",
        "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
        "        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n",
        "        drop (float, optional): Dropout rate. Default: 0.0\n",
        "        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n",
        "        drop_path (float | list[float], optional): Stochastic depth rate. Default: 0.0\n",
        "        norm_layer (layers.Layer, optional): Normalization layer. Default: layers.LayerNormalization\n",
        "        downsample (layers.Layer | None, optional): Downsample layer at the end of the layer. Default: None\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim, out_dim, input_resolution, depth, num_heads=4,\n",
        "                 head_dim=None, window_size=7, mlp_ratio=4.0, qkv_bias=True,\n",
        "                 drop=0.0, attn_drop=0.0, drop_path=0.0,\n",
        "                 norm_layer=LayerNormalization, downsample=None, **kwargs):\n",
        "\n",
        "        super(BasicLayer, self).__init__(kwargs)\n",
        "\n",
        "        self.dim = dim\n",
        "        self.input_resolution = input_resolution\n",
        "        self.depth = depth\n",
        "\n",
        "        # build blocks\n",
        "        blocks = [\n",
        "            SwinTransformerBlock(\n",
        "                dim=dim,\n",
        "                input_resolution=input_resolution,\n",
        "                num_heads=num_heads,\n",
        "                head_dim=head_dim,\n",
        "                window_size=window_size,\n",
        "                shift_size=0 if (i % 2 == 0) else window_size // 2,\n",
        "                mlp_ratio=mlp_ratio,\n",
        "                qkv_bias=qkv_bias,\n",
        "                drop=drop,\n",
        "                attn_drop=attn_drop,\n",
        "                drop_path=drop_path[i]\n",
        "                if isinstance(drop_path, list)\n",
        "                else drop_path,\n",
        "                norm_layer=norm_layer,\n",
        "                name=f\"swin_transformer_block_{i}\",\n",
        "            )\n",
        "            for i in range(depth)\n",
        "        ]\n",
        "        self.blocks = blocks\n",
        "\n",
        "        # patch merging layer\n",
        "        if downsample is not None:\n",
        "            self.downsample = downsample(\n",
        "                input_resolution,\n",
        "                dim=dim,\n",
        "             #   norm_layer=norm_layer,\n",
        "                name=\"downsample\"\n",
        "                )\n",
        "        else:\n",
        "            self.downsample = None\n",
        "\n",
        "    def call(self, x) :\n",
        "\n",
        "        for i, block in enumerate(self.blocks):\n",
        "            x = block(x)\n",
        "        if self.downsample is not None:\n",
        "            x = self.downsample(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T11:54:14.835959Z",
          "iopub.status.busy": "2023-07-11T11:54:14.835165Z",
          "iopub.status.idle": "2023-07-11T11:54:14.849781Z",
          "shell.execute_reply": "2023-07-11T11:54:14.848358Z",
          "shell.execute_reply.started": "2023-07-11T11:54:14.835916Z"
        },
        "id": "mNIw_4cM1rbk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class PatchEmbed(keras.layers.Layer):\n",
        "    \"\"\" Image to Patch Embedding\n",
        "    Args:\n",
        "        img_size (int): Image size.  Default: 224.\n",
        "        patch_size (int): Patch token size. Default: 4.\n",
        "        in_chans (int): Number of input image channels. Default: 3.\n",
        "        embed_dim (int): Number of linear projection output channels. Default: 96.\n",
        "        norm_layer (nn.Module, optional): Normalization layer. Default: None\n",
        "    \"\"\"\n",
        "    def __init__(self, img_size=(224, 224), patch_size=(4, 4), in_chans=3, embed_dim=96, norm_layer=None, **kwargs):\n",
        "        super(PatchEmbed, self).__init__(**kwargs)\n",
        "        self.img_size = (img_size)\n",
        "        self.patch_size = (patch_size)\n",
        "        patches_resolution = [img_size[0] // patch_size[0], img_size[1] // patch_size[1]]\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.patches_resolution = patches_resolution\n",
        "        self.num_patches = patches_resolution[0] * patches_resolution[1]\n",
        "\n",
        "        self.in_chans = in_chans\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        self.proj = Conv2D(filters=embed_dim,\n",
        "                           kernel_size=patch_size,\n",
        "                           strides=patch_size,\n",
        "                           name=\"proj\"\n",
        "                          )\n",
        "        if norm_layer is not None:\n",
        "            self.norm = norm_layer(epsilon=1e-5)\n",
        "        else:\n",
        "            self.norm = None\n",
        "\n",
        "    def call(self, x):\n",
        "        B, H, W, C = tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2], tf.shape(x)[3]\n",
        "      #  assert H == self.img_size[0] and W == self.img_size[1], \\\n",
        "       #     f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
        "\n",
        "        x = self.proj(x)\n",
        "        x = tf.reshape(x, shape=[-1, (H // self.patch_size[0]) * (W // self.patch_size[0]), self.embed_dim])\n",
        "        if self.norm is not None:\n",
        "            x = self.norm(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "bkboKvSd1rbm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T11:54:16.039473Z",
          "iopub.status.busy": "2023-07-11T11:54:16.038966Z",
          "iopub.status.idle": "2023-07-11T11:54:16.063587Z",
          "shell.execute_reply": "2023-07-11T11:54:16.062617Z",
          "shell.execute_reply.started": "2023-07-11T11:54:16.039438Z"
        },
        "id": "5srRPVTE1rbo",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def to_ntuple(n):\n",
        "    def parse(x):\n",
        "        if isinstance(x, collections.abc.Iterable):\n",
        "            return x\n",
        "        return tuple(repeat(x, n))\n",
        "\n",
        "    return parse\n",
        "\n",
        "\n",
        "class SwinTransformer(keras.Model):\n",
        "    \"\"\"Swin Transformer\n",
        "        A TensorFlow impl of : `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows`  -\n",
        "          https://arxiv.org/pdf/2103.14030\n",
        "\n",
        "    Args:\n",
        "        img_size (int | tuple(int)): Input image size. Default 224\n",
        "        patch_size (int | tuple(int)): Patch size. Default: 4\n",
        "        num_classes (int): Number of classes for classification head. Default: 1000\n",
        "        embed_dim (int): Patch embedding dimension. Default: 96\n",
        "        depths (tuple(int)): Depth of each Swin Transformer layer.\n",
        "        num_heads (tuple(int)): Number of attention heads in different layers.\n",
        "        head_dim (int, tuple(int)):\n",
        "        window_size (int): Window size. Default: 7\n",
        "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4\n",
        "        qkv_bias (bool): If True, add a learnable bias to query, key, value. Default: True\n",
        "        drop_rate (float): Dropout rate. Default: 0\n",
        "        attn_drop_rate (float): Attention dropout rate. Default: 0\n",
        "        drop_path_rate (float): Stochastic depth rate. Default: 0.1\n",
        "        norm_layer (layers.Layer): Normalization layer. Default: layers.LayerNormalization.\n",
        "        ape (bool): If True, add absolute position embedding to the patch embedding. Default: False\n",
        "        patch_norm (bool): If True, add normalization after patch embedding. Default: True\n",
        "        pre_logits (bool): If True, return model without classification head. Default: False\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, img_size=224, patch_size=4, num_classes=1000,\n",
        "                 global_pool=\"avg\", embed_dim=96, depths=(2, 2, 6, 2),\n",
        "                 num_heads=(3, 6, 12, 24), head_dim=None, window_size=7,\n",
        "                 mlp_ratio=4.0, qkv_bias=True, drop_rate=0.0, attn_drop_rate=0.0,\n",
        "                 drop_path_rate=0.1, norm_layer=LayerNormalization,\n",
        "                 ape=False, patch_norm=True, in_channels=3, include_top=True, **kwargs,):\n",
        "\n",
        "        super(SwinTransformer, self).__init__(**kwargs)\n",
        "\n",
        "        self.img_size = (\n",
        "            img_size\n",
        "            if isinstance(img_size, collections.abc.Iterable)\n",
        "            else (img_size, img_size)\n",
        "        )\n",
        "        self.patch_size = (\n",
        "            patch_size\n",
        "            if isinstance(patch_size, collections.abc.Iterable)\n",
        "            else (patch_size, patch_size)\n",
        "        )\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.global_pool = global_pool\n",
        "        self.num_layers = len(depths)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_features = int(embed_dim * 2 ** (self.num_layers - 1))\n",
        "        self.ape = ape\n",
        "        self.patch_norm = patch_norm\n",
        "        self.in_channels = in_channels\n",
        "        self.include_top = include_top\n",
        "\n",
        "        self.patch_embed = PatchEmbed(\n",
        "            img_size=self.img_size,\n",
        "            patch_size=self.patch_size,\n",
        "            in_chans=in_channels,\n",
        "            embed_dim=embed_dim,\n",
        "            norm_layer=norm_layer if self.patch_norm else None,\n",
        "            name=\"patch_embedding\"\n",
        "        )\n",
        "\n",
        "        self.patch_grid = (\n",
        "            self.img_size[0] // self.patch_size[0],\n",
        "            self.img_size[1] // self.patch_size[1],\n",
        "        )\n",
        "        self.num_patches = self.patch_grid[0] * self.patch_grid[1]\n",
        "\n",
        "        # absolute position embedding\n",
        "        if self.ape:\n",
        "            self.absolute_pos_embed = tf.Variable(\n",
        "                tf.zeros((1, self.num_patches, self.embed_dim)),\n",
        "                trainable=True,\n",
        "                name=\"absolute_pos_embed\",\n",
        "            )\n",
        "        else:\n",
        "            self.absolute_pos_embed = None\n",
        "        self.pos_drop = Dropout(drop_rate)\n",
        "\n",
        "        # build layers\n",
        "        if not isinstance(self.embed_dim, (tuple, list)):\n",
        "            self.embed_dim = [\n",
        "                int(self.embed_dim * 2 ** i) for i in range(self.num_layers)\n",
        "            ]\n",
        "        embed_out_dim = self.embed_dim[1:] + [None]\n",
        "        head_dim = to_ntuple(self.num_layers)(head_dim)\n",
        "        window_size = to_ntuple(self.num_layers)(window_size)\n",
        "        mlp_ratio = to_ntuple(self.num_layers)(mlp_ratio)\n",
        "        dpr = [\n",
        "            float(x) for x in tf.linspace(0.0, drop_path_rate, sum(depths))\n",
        "        ]  # stochastic depth decay rule\n",
        "\n",
        "        layers = [\n",
        "            BasicLayer(\n",
        "                dim=self.embed_dim[i],\n",
        "                out_dim=embed_out_dim[i],\n",
        "                input_resolution=(\n",
        "                    self.patch_grid[0] // (2 ** i),\n",
        "                    self.patch_grid[1] // (2 ** i),\n",
        "                ),\n",
        "                depth=depths[i],\n",
        "                num_heads=num_heads[i],\n",
        "                head_dim=head_dim[i],\n",
        "                window_size=window_size[i],\n",
        "                mlp_ratio=mlp_ratio[i],\n",
        "                qkv_bias=qkv_bias,\n",
        "                drop=drop_rate,\n",
        "                attn_drop=attn_drop_rate,\n",
        "                drop_path=dpr[sum(depths[:i]) : sum(depths[: i + 1])],\n",
        "                norm_layer=norm_layer,\n",
        "               # downsample=PatchMerging if (i < self.num_layers - 1) else None,\n",
        "                downsample=PatchMerging if (i < self.num_layers - 1) else None,\n",
        "                name=f\"layer{i}\",\n",
        "            )\n",
        "            for i in range(self.num_layers)\n",
        "        ]\n",
        "        self.swin_layers = layers\n",
        "        self.norm = norm_layer(epsilon=1e-5)\n",
        "\n",
        "        if self.include_top:\n",
        "            self.head = Dense(num_classes, name=\"classification_head\")\n",
        "\n",
        "    def forward_features(self, x):\n",
        "        x = self.patch_embed(x)\n",
        "        if self.absolute_pos_embed is not None:\n",
        "            x = x + self.absolute_pos_embed\n",
        "        x = self.pos_drop(x)\n",
        "\n",
        "        for swin_layer in self.swin_layers:\n",
        "            x = swin_layer(x)\n",
        "\n",
        "        x = self.norm(x)  # [B, L, C]\n",
        "        return x\n",
        "\n",
        "    def forward_head(self, x):\n",
        "        if self.global_pool == \"avg\":\n",
        "            x = tf.reduce_mean(x, axis=1)\n",
        "        return x if not self.include_top else self.head(x)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.forward_features(x)\n",
        "        x = self.forward_head(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T11:54:17.436985Z",
          "iopub.status.busy": "2023-07-11T11:54:17.436624Z",
          "iopub.status.idle": "2023-07-11T11:54:17.702744Z",
          "shell.execute_reply": "2023-07-11T11:54:17.701689Z",
          "shell.execute_reply.started": "2023-07-11T11:54:17.436954Z"
        },
        "id": "46TJWWW71rcE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "m = SwinTransformer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T11:54:19.175568Z",
          "iopub.status.busy": "2023-07-11T11:54:19.174795Z",
          "iopub.status.idle": "2023-07-11T11:54:19.644909Z",
          "shell.execute_reply": "2023-07-11T11:54:19.643917Z",
          "shell.execute_reply.started": "2023-07-11T11:54:19.175528Z"
        },
        "id": "3cyA5Se01rcI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "out = m(np.zeros((1, 224, 224, 3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T11:54:21.345098Z",
          "iopub.status.busy": "2023-07-11T11:54:21.344696Z",
          "iopub.status.idle": "2023-07-11T11:54:21.373027Z",
          "shell.execute_reply": "2023-07-11T11:54:21.371989Z",
          "shell.execute_reply.started": "2023-07-11T11:54:21.345063Z"
        },
        "id": "FKojwuT41rcJ",
        "outputId": "2da2b09e-a735-4f47-b149-5f348ff88f59",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28288354"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m.count_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69i7VldU1rcU",
        "outputId": "e396e331-69b5-4569-ab99-6436c7009c1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"swin_transformer_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " patch_embedding (PatchEmbed  multiple                 4896      \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_74 (Dropout)        multiple                  0         \n",
            "                                                                 \n",
            " basic_layer_8 (BasicLayer)  multiple                  299190    \n",
            "                                                                 \n",
            " basic_layer_9 (BasicLayer)  multiple                  1188204   \n",
            "                                                                 \n",
            " basic_layer_10 (BasicLayer)  multiple                 11841672  \n",
            "                                                                 \n",
            " basic_layer_11 (BasicLayer)  multiple                 14183856  \n",
            "                                                                 \n",
            " layer_normalization_88 (Lay  multiple                 1536      \n",
            " erNormalization)                                                \n",
            "                                                                 \n",
            " classification_head (Dense)  multiple                 769000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,288,354\n",
            "Trainable params: 28,288,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "m.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T11:47:14.777406Z",
          "iopub.status.busy": "2023-07-11T11:47:14.777052Z",
          "iopub.status.idle": "2023-07-11T11:47:25.937190Z",
          "shell.execute_reply": "2023-07-11T11:47:25.935971Z",
          "shell.execute_reply.started": "2023-07-11T11:47:14.777378Z"
        },
        "id": "IHPhRaOy1rcY",
        "outputId": "c4844ef7-ed4b-43b1-8dfa-a8a3f9f75ebc",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install timm --quiet\n",
        "!pip install transformers --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T11:47:25.940419Z",
          "iopub.status.busy": "2023-07-11T11:47:25.939937Z",
          "iopub.status.idle": "2023-07-11T11:47:29.620825Z",
          "shell.execute_reply": "2023-07-11T11:47:29.619790Z",
          "shell.execute_reply.started": "2023-07-11T11:47:25.940380Z"
        },
        "id": "rkgXMuY61rcZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "from transformers import SwinModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "bca517a5ba764b90a4b24c1431201024",
            "b973381c9e394b6ebc3fb6d46822d56c",
            "ef28f088dae34ecf8f8adbaf8fe12fe1",
            "00671bb391a94523849a1034e05d3d84",
            "930f892dfd064fb184678530d142f7f1",
            "b3dfca3fd7c24a7d9af9b5b567e8e7de",
            "8639e6d6886242509ebe800fddcc9db1",
            "8ad91a92bd88438287b8dc200ddf74c5",
            "bb43130325ec4371903c47cb1ef71ea5",
            "df094d7b1f2e468abeb5e8f4e6039aff",
            "08561377ada34f87857910606baf9972",
            "8c431fd8bf474adb9fe1610ac6076939",
            "4eadc7dd919448ba9458ac118553507e",
            "94efbda56be9472a8a304da8d98bf920",
            "9dd0a9087c6f42f7994b55927ecda82b",
            "df2a9429a17142d7aa359f9441f03c19",
            "59e5972120cd4b308b129c0baafc49e3",
            "532714951f6e4a23a713e3756ccc63f4",
            "15fa62bf9afc426dac431ca12f27a481",
            "9b4ff79d09b54801b38fb06b818e9fb7",
            "6a4d7a9e709e41a5a70be4e09ab39070",
            "a7ad422ef3aa4bf3b5b14e65a96e8dfe"
          ]
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T11:47:29.622785Z",
          "iopub.status.busy": "2023-07-11T11:47:29.622433Z",
          "iopub.status.idle": "2023-07-11T11:47:30.987903Z",
          "shell.execute_reply": "2023-07-11T11:47:30.986970Z",
          "shell.execute_reply.started": "2023-07-11T11:47:29.622749Z"
        },
        "id": "D7z_Auzk1rcf",
        "outputId": "a1b16d06-3550-4713-a0ac-32d10462a9a2",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bca517a5ba764b90a4b24c1431201024",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/71.8k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c431fd8bf474adb9fe1610ac6076939",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/113M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at microsoft/swin-tiny-patch4-window7-224 were not used when initializing SwinModel: ['classifier.weight', 'classifier.bias']\n",
            "- This IS expected if you are initializing SwinModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing SwinModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "pt_model = SwinModel.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T02:22:00.670776Z",
          "iopub.status.busy": "2023-07-11T02:22:00.670299Z",
          "iopub.status.idle": "2023-07-11T02:22:00.686665Z",
          "shell.execute_reply": "2023-07-11T02:22:00.685746Z",
          "shell.execute_reply.started": "2023-07-11T02:22:00.670741Z"
        },
        "id": "-pDLpBw41rcm",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "np_state_dict = pt_model.state_dict()\n",
        "pt_model_dict = {k: np_state_dict[k].numpy() for k in np_state_dict}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T02:22:25.420555Z",
          "iopub.status.busy": "2023-07-11T02:22:25.420092Z",
          "iopub.status.idle": "2023-07-11T02:22:25.432123Z",
          "shell.execute_reply": "2023-07-11T02:22:25.431172Z",
          "shell.execute_reply.started": "2023-07-11T02:22:25.420516Z"
        },
        "id": "dF3oGSLn1rcn",
        "outputId": "30b85e1e-6388-4fb3-de51-225a2a0801fd",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['embeddings.patch_embeddings.projection.weight', 'embeddings.patch_embeddings.projection.bias', 'embeddings.norm.weight', 'embeddings.norm.bias', 'encoder.layers.0.blocks.0.layernorm_before.weight', 'encoder.layers.0.blocks.0.layernorm_before.bias', 'encoder.layers.0.blocks.0.attention.self.relative_position_bias_table', 'encoder.layers.0.blocks.0.attention.self.relative_position_index', 'encoder.layers.0.blocks.0.attention.self.query.weight', 'encoder.layers.0.blocks.0.attention.self.query.bias', 'encoder.layers.0.blocks.0.attention.self.key.weight', 'encoder.layers.0.blocks.0.attention.self.key.bias', 'encoder.layers.0.blocks.0.attention.self.value.weight', 'encoder.layers.0.blocks.0.attention.self.value.bias', 'encoder.layers.0.blocks.0.attention.output.dense.weight', 'encoder.layers.0.blocks.0.attention.output.dense.bias', 'encoder.layers.0.blocks.0.layernorm_after.weight', 'encoder.layers.0.blocks.0.layernorm_after.bias', 'encoder.layers.0.blocks.0.intermediate.dense.weight', 'encoder.layers.0.blocks.0.intermediate.dense.bias', 'encoder.layers.0.blocks.0.output.dense.weight', 'encoder.layers.0.blocks.0.output.dense.bias', 'encoder.layers.0.blocks.1.layernorm_before.weight', 'encoder.layers.0.blocks.1.layernorm_before.bias', 'encoder.layers.0.blocks.1.attention.self.relative_position_bias_table', 'encoder.layers.0.blocks.1.attention.self.relative_position_index', 'encoder.layers.0.blocks.1.attention.self.query.weight', 'encoder.layers.0.blocks.1.attention.self.query.bias', 'encoder.layers.0.blocks.1.attention.self.key.weight', 'encoder.layers.0.blocks.1.attention.self.key.bias', 'encoder.layers.0.blocks.1.attention.self.value.weight', 'encoder.layers.0.blocks.1.attention.self.value.bias', 'encoder.layers.0.blocks.1.attention.output.dense.weight', 'encoder.layers.0.blocks.1.attention.output.dense.bias', 'encoder.layers.0.blocks.1.layernorm_after.weight', 'encoder.layers.0.blocks.1.layernorm_after.bias', 'encoder.layers.0.blocks.1.intermediate.dense.weight', 'encoder.layers.0.blocks.1.intermediate.dense.bias', 'encoder.layers.0.blocks.1.output.dense.weight', 'encoder.layers.0.blocks.1.output.dense.bias', 'encoder.layers.0.downsample.reduction.weight', 'encoder.layers.0.downsample.norm.weight', 'encoder.layers.0.downsample.norm.bias', 'encoder.layers.1.blocks.0.layernorm_before.weight', 'encoder.layers.1.blocks.0.layernorm_before.bias', 'encoder.layers.1.blocks.0.attention.self.relative_position_bias_table', 'encoder.layers.1.blocks.0.attention.self.relative_position_index', 'encoder.layers.1.blocks.0.attention.self.query.weight', 'encoder.layers.1.blocks.0.attention.self.query.bias', 'encoder.layers.1.blocks.0.attention.self.key.weight', 'encoder.layers.1.blocks.0.attention.self.key.bias', 'encoder.layers.1.blocks.0.attention.self.value.weight', 'encoder.layers.1.blocks.0.attention.self.value.bias', 'encoder.layers.1.blocks.0.attention.output.dense.weight', 'encoder.layers.1.blocks.0.attention.output.dense.bias', 'encoder.layers.1.blocks.0.layernorm_after.weight', 'encoder.layers.1.blocks.0.layernorm_after.bias', 'encoder.layers.1.blocks.0.intermediate.dense.weight', 'encoder.layers.1.blocks.0.intermediate.dense.bias', 'encoder.layers.1.blocks.0.output.dense.weight', 'encoder.layers.1.blocks.0.output.dense.bias', 'encoder.layers.1.blocks.1.layernorm_before.weight', 'encoder.layers.1.blocks.1.layernorm_before.bias', 'encoder.layers.1.blocks.1.attention.self.relative_position_bias_table', 'encoder.layers.1.blocks.1.attention.self.relative_position_index', 'encoder.layers.1.blocks.1.attention.self.query.weight', 'encoder.layers.1.blocks.1.attention.self.query.bias', 'encoder.layers.1.blocks.1.attention.self.key.weight', 'encoder.layers.1.blocks.1.attention.self.key.bias', 'encoder.layers.1.blocks.1.attention.self.value.weight', 'encoder.layers.1.blocks.1.attention.self.value.bias', 'encoder.layers.1.blocks.1.attention.output.dense.weight', 'encoder.layers.1.blocks.1.attention.output.dense.bias', 'encoder.layers.1.blocks.1.layernorm_after.weight', 'encoder.layers.1.blocks.1.layernorm_after.bias', 'encoder.layers.1.blocks.1.intermediate.dense.weight', 'encoder.layers.1.blocks.1.intermediate.dense.bias', 'encoder.layers.1.blocks.1.output.dense.weight', 'encoder.layers.1.blocks.1.output.dense.bias', 'encoder.layers.1.downsample.reduction.weight', 'encoder.layers.1.downsample.norm.weight', 'encoder.layers.1.downsample.norm.bias', 'encoder.layers.2.blocks.0.layernorm_before.weight', 'encoder.layers.2.blocks.0.layernorm_before.bias', 'encoder.layers.2.blocks.0.attention.self.relative_position_bias_table', 'encoder.layers.2.blocks.0.attention.self.relative_position_index', 'encoder.layers.2.blocks.0.attention.self.query.weight', 'encoder.layers.2.blocks.0.attention.self.query.bias', 'encoder.layers.2.blocks.0.attention.self.key.weight', 'encoder.layers.2.blocks.0.attention.self.key.bias', 'encoder.layers.2.blocks.0.attention.self.value.weight', 'encoder.layers.2.blocks.0.attention.self.value.bias', 'encoder.layers.2.blocks.0.attention.output.dense.weight', 'encoder.layers.2.blocks.0.attention.output.dense.bias', 'encoder.layers.2.blocks.0.layernorm_after.weight', 'encoder.layers.2.blocks.0.layernorm_after.bias', 'encoder.layers.2.blocks.0.intermediate.dense.weight', 'encoder.layers.2.blocks.0.intermediate.dense.bias', 'encoder.layers.2.blocks.0.output.dense.weight', 'encoder.layers.2.blocks.0.output.dense.bias', 'encoder.layers.2.blocks.1.layernorm_before.weight', 'encoder.layers.2.blocks.1.layernorm_before.bias', 'encoder.layers.2.blocks.1.attention.self.relative_position_bias_table', 'encoder.layers.2.blocks.1.attention.self.relative_position_index', 'encoder.layers.2.blocks.1.attention.self.query.weight', 'encoder.layers.2.blocks.1.attention.self.query.bias', 'encoder.layers.2.blocks.1.attention.self.key.weight', 'encoder.layers.2.blocks.1.attention.self.key.bias', 'encoder.layers.2.blocks.1.attention.self.value.weight', 'encoder.layers.2.blocks.1.attention.self.value.bias', 'encoder.layers.2.blocks.1.attention.output.dense.weight', 'encoder.layers.2.blocks.1.attention.output.dense.bias', 'encoder.layers.2.blocks.1.layernorm_after.weight', 'encoder.layers.2.blocks.1.layernorm_after.bias', 'encoder.layers.2.blocks.1.intermediate.dense.weight', 'encoder.layers.2.blocks.1.intermediate.dense.bias', 'encoder.layers.2.blocks.1.output.dense.weight', 'encoder.layers.2.blocks.1.output.dense.bias', 'encoder.layers.2.blocks.2.layernorm_before.weight', 'encoder.layers.2.blocks.2.layernorm_before.bias', 'encoder.layers.2.blocks.2.attention.self.relative_position_bias_table', 'encoder.layers.2.blocks.2.attention.self.relative_position_index', 'encoder.layers.2.blocks.2.attention.self.query.weight', 'encoder.layers.2.blocks.2.attention.self.query.bias', 'encoder.layers.2.blocks.2.attention.self.key.weight', 'encoder.layers.2.blocks.2.attention.self.key.bias', 'encoder.layers.2.blocks.2.attention.self.value.weight', 'encoder.layers.2.blocks.2.attention.self.value.bias', 'encoder.layers.2.blocks.2.attention.output.dense.weight', 'encoder.layers.2.blocks.2.attention.output.dense.bias', 'encoder.layers.2.blocks.2.layernorm_after.weight', 'encoder.layers.2.blocks.2.layernorm_after.bias', 'encoder.layers.2.blocks.2.intermediate.dense.weight', 'encoder.layers.2.blocks.2.intermediate.dense.bias', 'encoder.layers.2.blocks.2.output.dense.weight', 'encoder.layers.2.blocks.2.output.dense.bias', 'encoder.layers.2.blocks.3.layernorm_before.weight', 'encoder.layers.2.blocks.3.layernorm_before.bias', 'encoder.layers.2.blocks.3.attention.self.relative_position_bias_table', 'encoder.layers.2.blocks.3.attention.self.relative_position_index', 'encoder.layers.2.blocks.3.attention.self.query.weight', 'encoder.layers.2.blocks.3.attention.self.query.bias', 'encoder.layers.2.blocks.3.attention.self.key.weight', 'encoder.layers.2.blocks.3.attention.self.key.bias', 'encoder.layers.2.blocks.3.attention.self.value.weight', 'encoder.layers.2.blocks.3.attention.self.value.bias', 'encoder.layers.2.blocks.3.attention.output.dense.weight', 'encoder.layers.2.blocks.3.attention.output.dense.bias', 'encoder.layers.2.blocks.3.layernorm_after.weight', 'encoder.layers.2.blocks.3.layernorm_after.bias', 'encoder.layers.2.blocks.3.intermediate.dense.weight', 'encoder.layers.2.blocks.3.intermediate.dense.bias', 'encoder.layers.2.blocks.3.output.dense.weight', 'encoder.layers.2.blocks.3.output.dense.bias', 'encoder.layers.2.blocks.4.layernorm_before.weight', 'encoder.layers.2.blocks.4.layernorm_before.bias', 'encoder.layers.2.blocks.4.attention.self.relative_position_bias_table', 'encoder.layers.2.blocks.4.attention.self.relative_position_index', 'encoder.layers.2.blocks.4.attention.self.query.weight', 'encoder.layers.2.blocks.4.attention.self.query.bias', 'encoder.layers.2.blocks.4.attention.self.key.weight', 'encoder.layers.2.blocks.4.attention.self.key.bias', 'encoder.layers.2.blocks.4.attention.self.value.weight', 'encoder.layers.2.blocks.4.attention.self.value.bias', 'encoder.layers.2.blocks.4.attention.output.dense.weight', 'encoder.layers.2.blocks.4.attention.output.dense.bias', 'encoder.layers.2.blocks.4.layernorm_after.weight', 'encoder.layers.2.blocks.4.layernorm_after.bias', 'encoder.layers.2.blocks.4.intermediate.dense.weight', 'encoder.layers.2.blocks.4.intermediate.dense.bias', 'encoder.layers.2.blocks.4.output.dense.weight', 'encoder.layers.2.blocks.4.output.dense.bias', 'encoder.layers.2.blocks.5.layernorm_before.weight', 'encoder.layers.2.blocks.5.layernorm_before.bias', 'encoder.layers.2.blocks.5.attention.self.relative_position_bias_table', 'encoder.layers.2.blocks.5.attention.self.relative_position_index', 'encoder.layers.2.blocks.5.attention.self.query.weight', 'encoder.layers.2.blocks.5.attention.self.query.bias', 'encoder.layers.2.blocks.5.attention.self.key.weight', 'encoder.layers.2.blocks.5.attention.self.key.bias', 'encoder.layers.2.blocks.5.attention.self.value.weight', 'encoder.layers.2.blocks.5.attention.self.value.bias', 'encoder.layers.2.blocks.5.attention.output.dense.weight', 'encoder.layers.2.blocks.5.attention.output.dense.bias', 'encoder.layers.2.blocks.5.layernorm_after.weight', 'encoder.layers.2.blocks.5.layernorm_after.bias', 'encoder.layers.2.blocks.5.intermediate.dense.weight', 'encoder.layers.2.blocks.5.intermediate.dense.bias', 'encoder.layers.2.blocks.5.output.dense.weight', 'encoder.layers.2.blocks.5.output.dense.bias', 'encoder.layers.2.downsample.reduction.weight', 'encoder.layers.2.downsample.norm.weight', 'encoder.layers.2.downsample.norm.bias', 'encoder.layers.3.blocks.0.layernorm_before.weight', 'encoder.layers.3.blocks.0.layernorm_before.bias', 'encoder.layers.3.blocks.0.attention.self.relative_position_bias_table', 'encoder.layers.3.blocks.0.attention.self.relative_position_index', 'encoder.layers.3.blocks.0.attention.self.query.weight', 'encoder.layers.3.blocks.0.attention.self.query.bias', 'encoder.layers.3.blocks.0.attention.self.key.weight', 'encoder.layers.3.blocks.0.attention.self.key.bias', 'encoder.layers.3.blocks.0.attention.self.value.weight', 'encoder.layers.3.blocks.0.attention.self.value.bias', 'encoder.layers.3.blocks.0.attention.output.dense.weight', 'encoder.layers.3.blocks.0.attention.output.dense.bias', 'encoder.layers.3.blocks.0.layernorm_after.weight', 'encoder.layers.3.blocks.0.layernorm_after.bias', 'encoder.layers.3.blocks.0.intermediate.dense.weight', 'encoder.layers.3.blocks.0.intermediate.dense.bias', 'encoder.layers.3.blocks.0.output.dense.weight', 'encoder.layers.3.blocks.0.output.dense.bias', 'encoder.layers.3.blocks.1.layernorm_before.weight', 'encoder.layers.3.blocks.1.layernorm_before.bias', 'encoder.layers.3.blocks.1.attention.self.relative_position_bias_table', 'encoder.layers.3.blocks.1.attention.self.relative_position_index', 'encoder.layers.3.blocks.1.attention.self.query.weight', 'encoder.layers.3.blocks.1.attention.self.query.bias', 'encoder.layers.3.blocks.1.attention.self.key.weight', 'encoder.layers.3.blocks.1.attention.self.key.bias', 'encoder.layers.3.blocks.1.attention.self.value.weight', 'encoder.layers.3.blocks.1.attention.self.value.bias', 'encoder.layers.3.blocks.1.attention.output.dense.weight', 'encoder.layers.3.blocks.1.attention.output.dense.bias', 'encoder.layers.3.blocks.1.layernorm_after.weight', 'encoder.layers.3.blocks.1.layernorm_after.bias', 'encoder.layers.3.blocks.1.intermediate.dense.weight', 'encoder.layers.3.blocks.1.intermediate.dense.bias', 'encoder.layers.3.blocks.1.output.dense.weight', 'encoder.layers.3.blocks.1.output.dense.bias', 'layernorm.weight', 'layernorm.bias'])"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pt_model_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSFoHQ-mGi6t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "d6c012fa08f841829d2401960150a6c2",
            "271917376ca24cab85f304eb56b056e0",
            "910c2d01df554a288e85120a3d5ff500",
            "18b404241f5f4492b4e6bb2bb325d776",
            "a0e6e482969b4b9788e4793c8bd7c6bc",
            "9261037a576c4900a850de9f28f4c796",
            "fda2a3ff78b5407e83b1d1efaaa483e6",
            "357fd4d350b548f88e35c4e0a26f6f93",
            "4573c5a914fe4ca9abc3404cf899a930",
            "17731e0d48044d5dacd9f5eef2fb99b4",
            "3afa12b6299b490482233111d327d295"
          ]
        },
        "id": "-ed8u5VuHCKk",
        "outputId": "ff640e41-5c6e-4c56-cc63-c2e5af970cfe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6c012fa08f841829d2401960150a6c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "timm_pt_model = timm.create_model(\n",
        "    model_name = \"swin_tiny_patch4_window7_224\",\n",
        "    pretrained = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_bO60kpmGiox"
      },
      "outputs": [],
      "source": [
        "timm_pt_model.eval()\n",
        "\n",
        "timm_np_state_dict = timm_pt_model.state_dict()\n",
        "tim_pt_model_dict = {k: timm_np_state_dict[k].numpy() for k in timm_np_state_dict}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LX4dRvLd1rco"
      },
      "outputs": [],
      "source": [
        "# layer -- represents the basiclayer\n",
        "# block -- represents the transformer blocks in basic layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DLgIUFpz1rcp"
      },
      "outputs": [],
      "source": [
        "from typing import Union\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def conv_transpose(w: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Transpose the weights of a PT conv layer so that it's comaptible with TF.\"\"\"\n",
        "    return w.transpose(2, 3, 1, 0)\n",
        "\n",
        "\n",
        "def modify_tf_block(\n",
        "    tf_component: Union[tf.keras.layers.Layer, tf.Variable, tf.Tensor],\n",
        "    pt_weight: np.ndarray,\n",
        "    pt_bias: np.ndarray = None,\n",
        "    is_attn: bool = False,\n",
        ") -> Union[tf.keras.layers.Layer, tf.Variable, tf.Tensor]:\n",
        "    \"\"\"General utility for modifying PT parameters for TF compatibility.\n",
        "    Applicable for Conv2D, Dense, tf.Variable, and LayerNormalization.\n",
        "    \"\"\"\n",
        "    pt_weight = (\n",
        "        conv_transpose(pt_weight)\n",
        "        if isinstance(tf_component, tf.keras.layers.Conv2D)\n",
        "        else pt_weight\n",
        "    )\n",
        "    pt_weight = (\n",
        "        pt_weight.transpose()\n",
        "        if isinstance(tf_component, tf.keras.layers.Dense) and not is_attn\n",
        "        else pt_weight\n",
        "    )\n",
        "\n",
        "    if isinstance(\n",
        "        tf_component, (tf.keras.layers.Dense, tf.keras.layers.Conv2D)\n",
        "    ):\n",
        "        tf_component.kernel.assign(tf.Variable(pt_weight))\n",
        "        if pt_bias is not None:\n",
        "            tf_component.bias.assign(tf.Variable(pt_bias))\n",
        "\n",
        "    elif isinstance(tf_component, tf.keras.layers.LayerNormalization):\n",
        "        tf_component.gamma.assign(tf.Variable(pt_weight))\n",
        "        tf_component.beta.assign(tf.Variable(pt_bias))\n",
        "\n",
        "    elif isinstance(tf_component, (tf.Variable)):\n",
        "        # For regular variables (tf.Variable).\n",
        "        tf_component.assign(tf.Variable(pt_weight))\n",
        "    else:\n",
        "        return tf.convert_to_tensor(pt_weight)\n",
        "\n",
        "    return tf_component"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "X8KTRvlo1rdd"
      },
      "outputs": [],
      "source": [
        "# main norm layer\n",
        "\n",
        "m.layers[-2] = modify_tf_block(\n",
        "        m.layers[-2],\n",
        "        pt_model_dict[\"layernorm.weight\"],\n",
        "        pt_model_dict[\"layernorm.bias\"],\n",
        "\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "J_wqDad71rdj"
      },
      "outputs": [],
      "source": [
        "# classification layer\n",
        "\n",
        "m.layers[-1] = modify_tf_block(\n",
        "        m.layers[-1],\n",
        "        tim_pt_model_dict[\"head.fc.weight\"],\n",
        "        tim_pt_model_dict[\"head.fc.bias\"],\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "OWEpR4YL1rdl"
      },
      "outputs": [],
      "source": [
        "# patch embed layer's projection\n",
        "\n",
        "m.layers[0].proj = modify_tf_block(\n",
        "    m.layers[0].proj,\n",
        "    np.array(pt_model_dict[\"embeddings.patch_embeddings.projection.weight\"]),\n",
        "    np.array(pt_model_dict[\"embeddings.patch_embeddings.projection.bias\"])\n",
        ")\n",
        "\n",
        "# patch embed layer's normalization\n",
        "m.layers[0].norm = modify_tf_block(\n",
        "    m.layers[0].norm,\n",
        "    np.array(pt_model_dict[\"embeddings.norm.weight\"]),\n",
        "    np.array(pt_model_dict[\"embeddings.norm.bias\"])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDTMrTiZ7QRk",
        "outputId": "792b7254-fb89-4c60-d423-94f61fb15a9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(384,)"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(pt_model_dict[f\"encoder.layers.{0}.downsample.norm.weight\"]).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Y7bepVcL79-A"
      },
      "outputs": [],
      "source": [
        "def modify_swin_layer(swin_layer, swin_layer_indx):\n",
        "\n",
        "  for block_indx, block in enumerate(swin_layer.layers):\n",
        "\n",
        "    # layer and block combined name\n",
        "    pt_block_name = f\"encoder.layers.{swin_layer_indx}.blocks.{block_indx}\"\n",
        "\n",
        "    if isinstance(block, PatchMerging):\n",
        "\n",
        "      norm_weight = np.array(pt_model_dict[f\"encoder.layers.{swin_layer_indx}.downsample.norm.weight\"]).transpose()\n",
        "      norm_bias = np.array(pt_model_dict[f\"encoder.layers.{swin_layer_indx}.downsample.norm.bias\"]).transpose()\n",
        "\n",
        "      block.norm.gamma.assign(tf.Variable(norm_weight))\n",
        "      block.norm.beta.assign(tf.Variable(norm_bias))\n",
        "\n",
        "      # reduction\n",
        "      block.reduction = modify_tf_block(\n",
        "          block.reduction,\n",
        "          np.array(pt_model_dict[f\"encoder.layers.{swin_layer_indx}.downsample.reduction.weight\"]),\n",
        "        )\n",
        "\n",
        "    if isinstance(block, SwinTransformerBlock):\n",
        "      n_norm = 1\n",
        "\n",
        "      for inner_transformer_block in block.layers:\n",
        "\n",
        "        # Normalization layer (norm1 and norm2)\n",
        "        if isinstance(inner_transformer_block, LayerNormalization):\n",
        "          if n_norm == 1:\n",
        "            norm_layer_name = pt_block_name + \".layernorm_before\"\n",
        "          else:\n",
        "            norm_layer_name = pt_block_name + \".layernorm_after\"\n",
        "\n",
        "         # print(inner_transformer_block)\n",
        "\n",
        "          inner_transformer_block = modify_tf_block(\n",
        "              inner_transformer_block,\n",
        "              np.array(pt_model_dict[ norm_layer_name + \".weight\"]),\n",
        "              np.array(pt_model_dict[ norm_layer_name + \".bias\"])\n",
        "          )\n",
        "          n_norm += 1\n",
        "\n",
        "        # window attention layer:\n",
        "        if isinstance(inner_transformer_block, WindowAttention):\n",
        "          # relative position bias table\n",
        "          inner_transformer_block.relative_position_bias_table = modify_tf_block(\n",
        "            inner_transformer_block.relative_position_bias_table,\n",
        "            np.array(pt_model_dict[pt_block_name + \".attention.self.relative_position_bias_table\"]),\n",
        "          )\n",
        "\n",
        "          # relative_position_index\n",
        "          inner_transformer_block.relative_position_index = modify_tf_block(\n",
        "            inner_transformer_block.relative_position_index,\n",
        "            np.array(pt_model_dict[pt_block_name + \".attention.self.relative_position_index\"]),\n",
        "          )\n",
        "\n",
        "          # qkv matrix\n",
        "          q_weight = np.array(pt_model_dict[pt_block_name + \".attention.self.query.weight\"])\n",
        "          k_weight = np.array(pt_model_dict[pt_block_name + \".attention.self.key.weight\"])\n",
        "          v_weight = np.array(pt_model_dict[pt_block_name + \".attention.self.value.weight\"])\n",
        "\n",
        "          qkv_weight = np.concatenate([q_weight, k_weight, v_weight])\n",
        "\n",
        "          q_bias = np.array(pt_model_dict[pt_block_name + \".attention.self.query.bias\"])\n",
        "          k_bias = np.array(pt_model_dict[pt_block_name + \".attention.self.key.bias\"])\n",
        "          v_bias = np.array(pt_model_dict[pt_block_name + \".attention.self.value.bias\"])\n",
        "\n",
        "          qkv_bias = np.concatenate([q_bias, k_bias, v_bias])\n",
        "\n",
        "          inner_transformer_block.qkv = modify_tf_block(\n",
        "            inner_transformer_block.qkv,\n",
        "            qkv_weight,\n",
        "            qkv_bias\n",
        "          )\n",
        "\n",
        "          # qkv projection\n",
        "          inner_transformer_block.proj = modify_tf_block(\n",
        "            inner_transformer_block.proj,\n",
        "            np.array(pt_model_dict[pt_block_name + \".attention.output.dense.weight\"]),\n",
        "            np.array(pt_model_dict[pt_block_name + \".attention.output.dense.bias\"])\n",
        "          )\n",
        "\n",
        "          # mlp layer\n",
        "        if isinstance(inner_transformer_block, MLP):\n",
        "          # fc1\n",
        "          inner_transformer_block.fc1 = modify_tf_block(\n",
        "            inner_transformer_block.fc1,\n",
        "            np.array(pt_model_dict[pt_block_name + \".intermediate.dense.weight\"]),\n",
        "            np.array(pt_model_dict[pt_block_name + \".intermediate.dense.bias\"])\n",
        "          )\n",
        "\n",
        "          # fc2\n",
        "          inner_transformer_block.fc2 = modify_tf_block(\n",
        "            inner_transformer_block.fc2,\n",
        "            np.array(pt_model_dict[pt_block_name + \".output.dense.weight\"]),\n",
        "            np.array(pt_model_dict[pt_block_name + \".output.dense.bias\"])\n",
        "          )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "JowGMdFf2uR1"
      },
      "outputs": [],
      "source": [
        "for i in range(4):\n",
        "  swin_layer = m.layers[2 + i]\n",
        "  modify_swin_layer(swin_layer, i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNhQYIPIa7qE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# porting the weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/shilu10/Swin-Transformer-TF2.git\n",
        "!mv Swin-Transformer-TF2 swins "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from swins.porting import port_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "port_weights(model_type=\"swin_base_patch4_window12_384\")\n",
        "!mkdir swin_pretrained_weights\n",
        "!mv /content/swin_tiny_patch4_window7_224.h5 swin_pretrained_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00671bb391a94523849a1034e05d3d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df094d7b1f2e468abeb5e8f4e6039aff",
            "placeholder": "​",
            "style": "IPY_MODEL_08561377ada34f87857910606baf9972",
            "value": " 71.8k/71.8k [00:00&lt;00:00, 3.38MB/s]"
          }
        },
        "08561377ada34f87857910606baf9972": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0886170a46524993976d9cc9b4022e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50f5e149c45e4ec19b3c6639c2eaafa5",
            "placeholder": "​",
            "style": "IPY_MODEL_2c25885725724a49b6fdf088ece6e309",
            "value": " 356M/356M [00:04&lt;00:00, 81.3MB/s]"
          }
        },
        "0ec54d3aba324edda879f93cdc96949f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a22e5f6505f412998e67ae5918fdfea",
              "IPY_MODEL_5a69ba5ce12f4e98b990fb0d8f8ad4cc",
              "IPY_MODEL_67ece4474f0343a1b4507514b2b3af1f"
            ],
            "layout": "IPY_MODEL_20b192b840394b6baa285b64c46579ec"
          }
        },
        "15fa62bf9afc426dac431ca12f27a481": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "163daa589e6a49018479883549cbcc18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17731e0d48044d5dacd9f5eef2fb99b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18b404241f5f4492b4e6bb2bb325d776": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17731e0d48044d5dacd9f5eef2fb99b4",
            "placeholder": "​",
            "style": "IPY_MODEL_3afa12b6299b490482233111d327d295",
            "value": " 114M/114M [00:01&lt;00:00, 48.6MB/s]"
          }
        },
        "1f09ef005a89420bb3f07089caea2161": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b11f42a482d34e7aafc92a125f3992e7",
            "placeholder": "​",
            "style": "IPY_MODEL_6ee66c7338624c2fbcc9df7036bb5436",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "20b192b840394b6baa285b64c46579ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "271917376ca24cab85f304eb56b056e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9261037a576c4900a850de9f28f4c796",
            "placeholder": "​",
            "style": "IPY_MODEL_fda2a3ff78b5407e83b1d1efaaa483e6",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "2c25885725724a49b6fdf088ece6e309": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "344e135278ac4ba083408fff0befeb10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "357fd4d350b548f88e35c4e0a26f6f93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3afa12b6299b490482233111d327d295": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c130363345040b2ad83cffc9eb49c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4573c5a914fe4ca9abc3404cf899a930": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "460e4a6a313c49c6a2f4642909ecc260": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4640eb3e78cb405c9edc012d03692fd7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47610e1a27f4488888fb85ae67315478": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a22e5f6505f412998e67ae5918fdfea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e7121e7f74a41a095e88275661d1e4b",
            "placeholder": "​",
            "style": "IPY_MODEL_e4d1fdf33d164c3e90a2f6749bf7f7bd",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "4eadc7dd919448ba9458ac118553507e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59e5972120cd4b308b129c0baafc49e3",
            "placeholder": "​",
            "style": "IPY_MODEL_532714951f6e4a23a713e3756ccc63f4",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "5031e0aaae44429183ff6889f75896ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50f5e149c45e4ec19b3c6639c2eaafa5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5182f70b38234e4a85a09c41eda73e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62e9fd642aa642bfbfb06be8823509d1",
              "IPY_MODEL_ddb7eb467fb545f0bf140830ef2370c2",
              "IPY_MODEL_76fcac5d57e341daa2c8dda8d8c546d3"
            ],
            "layout": "IPY_MODEL_47610e1a27f4488888fb85ae67315478"
          }
        },
        "532714951f6e4a23a713e3756ccc63f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59e5972120cd4b308b129c0baafc49e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a69ba5ce12f4e98b990fb0d8f8ad4cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dea50edaa5c426aa2198a16ff95ad3e",
            "max": 71816,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_460e4a6a313c49c6a2f4642909ecc260",
            "value": 71816
          }
        },
        "5d06094a53874ab88c2a91d2e37f2c11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62e9fd642aa642bfbfb06be8823509d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5911321d8fb4d359b0e965631acddb3",
            "placeholder": "​",
            "style": "IPY_MODEL_3c130363345040b2ad83cffc9eb49c9e",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "67ece4474f0343a1b4507514b2b3af1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ada7c3ab7664e93b13b4f79cc761669",
            "placeholder": "​",
            "style": "IPY_MODEL_ac237647eacf43bfb5c82091eec428e1",
            "value": " 71.8k/71.8k [00:00&lt;00:00, 3.40MB/s]"
          }
        },
        "6a4d7a9e709e41a5a70be4e09ab39070": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dea50edaa5c426aa2198a16ff95ad3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ee66c7338624c2fbcc9df7036bb5436": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76fcac5d57e341daa2c8dda8d8c546d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_344e135278ac4ba083408fff0befeb10",
            "placeholder": "​",
            "style": "IPY_MODEL_5031e0aaae44429183ff6889f75896ba",
            "value": " 365M/365M [00:06&lt;00:00, 141MB/s]"
          }
        },
        "7e7121e7f74a41a095e88275661d1e4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8639e6d6886242509ebe800fddcc9db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ad91a92bd88438287b8dc200ddf74c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ada7c3ab7664e93b13b4f79cc761669": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c431fd8bf474adb9fe1610ac6076939": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4eadc7dd919448ba9458ac118553507e",
              "IPY_MODEL_94efbda56be9472a8a304da8d98bf920",
              "IPY_MODEL_9dd0a9087c6f42f7994b55927ecda82b"
            ],
            "layout": "IPY_MODEL_df2a9429a17142d7aa359f9441f03c19"
          }
        },
        "910c2d01df554a288e85120a3d5ff500": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_357fd4d350b548f88e35c4e0a26f6f93",
            "max": 114286722,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4573c5a914fe4ca9abc3404cf899a930",
            "value": 114286722
          }
        },
        "9261037a576c4900a850de9f28f4c796": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "930f892dfd064fb184678530d142f7f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94efbda56be9472a8a304da8d98bf920": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15fa62bf9afc426dac431ca12f27a481",
            "max": 113476015,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b4ff79d09b54801b38fb06b818e9fb7",
            "value": 113476015
          }
        },
        "9b4ff79d09b54801b38fb06b818e9fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ba7e2d5e4794f1e94b52c7def2fb987": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dd0a9087c6f42f7994b55927ecda82b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a4d7a9e709e41a5a70be4e09ab39070",
            "placeholder": "​",
            "style": "IPY_MODEL_a7ad422ef3aa4bf3b5b14e65a96e8dfe",
            "value": " 113M/113M [00:03&lt;00:00, 41.9MB/s]"
          }
        },
        "a0e6e482969b4b9788e4793c8bd7c6bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5911321d8fb4d359b0e965631acddb3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7ad422ef3aa4bf3b5b14e65a96e8dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aabd14288abc43919e9be7762efe8003": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4640eb3e78cb405c9edc012d03692fd7",
            "max": 355775743,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d95a3d9dcf724879a6d13c98dd1d3b93",
            "value": 355775743
          }
        },
        "ac237647eacf43bfb5c82091eec428e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b11f42a482d34e7aafc92a125f3992e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3dfca3fd7c24a7d9af9b5b567e8e7de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b973381c9e394b6ebc3fb6d46822d56c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3dfca3fd7c24a7d9af9b5b567e8e7de",
            "placeholder": "​",
            "style": "IPY_MODEL_8639e6d6886242509ebe800fddcc9db1",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "bb43130325ec4371903c47cb1ef71ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bca517a5ba764b90a4b24c1431201024": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b973381c9e394b6ebc3fb6d46822d56c",
              "IPY_MODEL_ef28f088dae34ecf8f8adbaf8fe12fe1",
              "IPY_MODEL_00671bb391a94523849a1034e05d3d84"
            ],
            "layout": "IPY_MODEL_930f892dfd064fb184678530d142f7f1"
          }
        },
        "d566e437a7474e41a61b94bc462ca635": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f09ef005a89420bb3f07089caea2161",
              "IPY_MODEL_aabd14288abc43919e9be7762efe8003",
              "IPY_MODEL_0886170a46524993976d9cc9b4022e25"
            ],
            "layout": "IPY_MODEL_9ba7e2d5e4794f1e94b52c7def2fb987"
          }
        },
        "d6c012fa08f841829d2401960150a6c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_271917376ca24cab85f304eb56b056e0",
              "IPY_MODEL_910c2d01df554a288e85120a3d5ff500",
              "IPY_MODEL_18b404241f5f4492b4e6bb2bb325d776"
            ],
            "layout": "IPY_MODEL_a0e6e482969b4b9788e4793c8bd7c6bc"
          }
        },
        "d95a3d9dcf724879a6d13c98dd1d3b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ddb7eb467fb545f0bf140830ef2370c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d06094a53874ab88c2a91d2e37f2c11",
            "max": 365255040,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_163daa589e6a49018479883549cbcc18",
            "value": 365255040
          }
        },
        "df094d7b1f2e468abeb5e8f4e6039aff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df2a9429a17142d7aa359f9441f03c19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4d1fdf33d164c3e90a2f6749bf7f7bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef28f088dae34ecf8f8adbaf8fe12fe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ad91a92bd88438287b8dc200ddf74c5",
            "max": 71813,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb43130325ec4371903c47cb1ef71ea5",
            "value": 71813
          }
        },
        "fda2a3ff78b5407e83b1d1efaaa483e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
